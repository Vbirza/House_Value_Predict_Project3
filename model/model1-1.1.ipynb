{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpi = pd.DataFrame(pd.read_csv('hpi_final.csv'))\n",
    "cpb = pd.DataFrame(pd.read_csv('cpb_final.csv'))\n",
    "bps = pd.DataFrame(pd.read_csv('building_permits_final.csv'))\n",
    "pop = pd.DataFrame(pd.read_csv('Population_Change.csv'))\n",
    "inc = pd.DataFrame(pd.read_csv('county_income.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pop[['pop_chg_yoy','Id2', 'year','one_year', 'two_years', 'three_years', 'four_years', 'five_years']]\n",
    "\n",
    "pop.one_year = pop.one_year.shift(-1)\n",
    "pop.two_years = pop.two_years.shift(-2)\n",
    "pop.three_years = pop.three_years.shift(-3)\n",
    "pop.four_years = pop.four_years.shift(-4)\n",
    "pop.five_years = pop.five_years.shift(-5)\n",
    "pop = pop.rename(columns = {\n",
    "    'Id2': 'county_code',\n",
    "    'one_year': 'one_year_pop',\n",
    "    'two_years': 'two_years_pop',\n",
    "    'three_years': 'three_years_pop',\n",
    "    'four_years': 'four_years_pop',\n",
    "    'five_years': 'five_years_pop'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc = inc[['county_code', 'year', 'hh_income']]\n",
    "\n",
    "gb = inc.groupby(['county_code', 'year']).mean()\n",
    "\n",
    "\n",
    "def percent_change(gb):\n",
    "    gb['one_year_inc']=gb['hh_income'].pct_change(periods=1).shift(-1)\n",
    "    gb['two_years_inc']=gb['hh_income'].pct_change(periods=2).shift(-2)\n",
    "    gb['three_years_inc']=gb['hh_income'].pct_change(periods=3).shift(-3)\n",
    "    gb['four_years_inc']=gb['hh_income'].pct_change(periods=4).shift(-4)\n",
    "    gb['five_years_inc']=gb['hh_income'].pct_change(periods=5).shift(-5)\n",
    "    \n",
    "    return gb\n",
    "\n",
    "inc = gb.groupby(level=0).apply(percent_change)\n",
    "\n",
    "inc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpi = hpi[['county', 'year', 'hpi','one_year', 'two_years', 'three_years',\n",
    "       'four_years', 'five_years'\n",
    "          ]]\n",
    "bps = bps[['date', 'county_code', 'single_units', 'total_units']]\n",
    "cpb = cpb[['county_code', 'year', 'EMP', 'ESTAB', 'PAYANN',\n",
    "           'one_year_emp',\n",
    "       'two_years_emp', 'three_years_emp', 'four_years_emp', 'five_years_emp',\n",
    "       'one_year_estab', 'two_years_estab', 'three_years_estab',\n",
    "       'four_years_estab', 'five_years_estab', 'one_year_pay', 'two_years_pay',\n",
    "       'three_years_pay', 'four_years_pay', 'five_years_pay'\n",
    "          ]]\n",
    "hpi.rename(columns={'county': 'county_code'}, inplace=True)\n",
    "bps.rename(columns={'date': 'year'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(hpi, cpb, how='inner', on=['county_code', 'year'])\n",
    "\n",
    "df1 = pd.merge(df, bps, how='inner', on=['county_code', 'year'])\n",
    "\n",
    "df2 = pd.merge(df1, pop, how='inner', on = ['county_code', 'year'])\n",
    "\n",
    "df3 = pd.merge(df2, inc.reset_index(), how=\"inner\", on = ['county_code', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.replace([np.inf, -np.inf], np.nan)\n",
    "df3 = df3.dropna()\n",
    "df3.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "cols = ['five_years','five_years_pop', 'five_years_inc']\n",
    "sns.pairplot(df3[cols], size = 2.5)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(df3, \n",
    "             y_vars=['five_years_pop', 'five_years_inc', 'five_years'],\n",
    "             x_vars=['hpi', 'EMP', 'ESTAB', 'hh_income'])\n",
    "g.map_lower(sns.kdeplot)\n",
    "g.map_upper(sns.kdeplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = sns.pairplot(df3, vars=['hpi','one_year', 'two_years','three_years', 'four_years', 'five_years'], \n",
    "                 diag_kind='kde')\n",
    "g1.map_lower(sns.kdeplot)\n",
    "g1.map_upper(sns.kdeplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = sns.pairplot(df3, vars=['hh_income','one_year_inc', 'two_years_inc','three_years_inc', 'four_years_inc', 'five_years_inc'], \n",
    "                 diag_kind='kde')\n",
    "g2.map_lower(sns.kdeplot)\n",
    "g2.map_upper(sns.kdeplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3 = sns.pairplot(df3, vars=['pop_chg_yoy','one_year_pop', 'two_years_pop','three_years_pop', 'four_years_pop', 'five_years_pop'], \n",
    "                 diag_kind='kde')\n",
    "g3.map_lower(sns.kdeplot)\n",
    "g3.map_upper(sns.kdeplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4 = sns.pairplot(df3, vars=['EMP','one_year_pop', 'two_years_pop','three_years_pop', 'four_years_pop', 'five_years_pop'], \n",
    "                 diag_kind='kde')\n",
    "g4.map_lower(sns.kdeplot)\n",
    "g4.map_upper(sns.kdeplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g5 = sns.pairplot(df3, \n",
    "                  x_vars=['one_year', 'two_years','three_years', 'four_years', 'five_years'],\n",
    "                  y_vars=['one_year_pop', 'two_years_pop','three_years_pop', 'four_years_pop', 'five_years_pop'], \n",
    "                 )\n",
    "g5.map_lower(sns.kdeplot)\n",
    "g5.map_upper(sns.kdeplot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df3[[\n",
    "    'EMP', 'ESTAB', 'PAYANN', 'single_units', 'total_units',\n",
    "    'one_year_emp', 'two_years_emp', 'three_years_emp', 'four_years_emp', 'five_years_emp',\n",
    "       'one_year_estab', 'two_years_estab', 'three_years_estab',\n",
    "       'four_years_estab', 'five_years_estab', 'one_year_pay', 'two_years_pay',\n",
    "       'three_years_pay', 'four_years_pay', 'five_years_pay',\n",
    "         'one_year_pop', 'one_year_inc', 'two_years_inc',\n",
    "    'three_years_inc','four_years_inc','five_years_inc',\n",
    "        'two_years_pop', 'three_years_pop', 'four_years_pop',\n",
    "    'five_years_pop', 'hh_income']].values\n",
    "\n",
    "l = [1.14383044e+01 5.14469879e+00 3.81888392e+00 2.50210240e+00\n",
    " 1.82401920e+00 1.28582056e+00 9.11751486e-01 6.39934740e-01\n",
    " 5.87864763e-01 4.69710199e-01 4.35471351e-01 3.46161050e-01\n",
    " 2.63954143e-01 2.04374344e-01 1.99134938e-01 1.86972212e-01\n",
    " 1.54114624e-01 1.00453651e-01 9.14101373e-02 7.14516724e-02\n",
    " 6.29874665e-02 5.26596066e-02 5.01520236e-02 4.87752355e-02\n",
    " 3.42196138e-02 3.16975608e-02 2.16271517e-02 1.27987425e-02\n",
    " 1.15001740e-02 4.56579480e-03 5.24164182e-04]\n",
    "\n",
    "y = df3[['five_years']].values\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_scaled)\n",
    "model.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = model.score(X_test_scaled, y_test_scaled)\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "lasso = Lasso(alpha=.01).fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "predictions = lasso.predict(X_test_scaled)\n",
    "\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = lasso.score(X_test_scaled, y_test_scaled)\n",
    "### END SOLUTION\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ridge = Ridge(alpha=.01).fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "predictions = ridge.predict(X_test_scaled)\n",
    "\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = ridge.score(X_test_scaled, y_test_scaled)\n",
    "### END SOLUTION\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "elasticnet = ElasticNet(alpha=.01).fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "predictions = elasticnet.predict(X_test_scaled)\n",
    "\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = elasticnet.score(X_test_scaled, y_test_scaled)\n",
    "### END SOLUTION\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "\n",
    "classifiers = [\n",
    "    svm.SVR(),\n",
    "#     linear_model.SGDRegressor(),\n",
    "    linear_model.BayesianRidge(),\n",
    "#     linear_model.LassoLars(),\n",
    "    linear_model.ARDRegression(),\n",
    "#     linear_model.PassiveAggressiveRegressor(),\n",
    "#     linear_model.TheilSenRegressor(),\n",
    "    linear_model.LinearRegression()]\n",
    "\n",
    "for item in classifiers:\n",
    "    print(item)\n",
    "    clf = item\n",
    "    clf.fit(X_train_scaled, y_train_scaled)\n",
    "    r2 = clf.score(X_test_scaled, y_test_scaled)\n",
    "    print(f'r2 score: {r2}')\n",
    "    print('----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=31)\n",
    "pca.fit(X_train_scaled)\n",
    "print(pca.)\n",
    "print('-----------------------------------------')\n",
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "pca.fit(X_train_scaled)\n",
    "X_pca = pca.transform(X_train_scaled)\n",
    "print(\"original shape:   \", X_train_scaled.shape)\n",
    "print(\"transformed shape:\", X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pca.inverse_transform(X_pca)\n",
    "plt.scatter(X_train_scaled[:, 0], X_train_scaled[:, 1], alpha=0.2)\n",
    "plt.scatter(X_new[:, 0],X_new[:, 1], alpha=0.8)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=31)\n",
    "Y_sklearn = sklearn_pca.fit_transform(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sklearn_pca.fit(X_train_scaled)\n",
    "print(\"\")\n",
    "print('-----------------------------------------')\n",
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from keras.layers import Dense, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df3[[\n",
    "    'EMP', 'ESTAB', 'PAYANN', 'single_units', 'total_units','hh_income','pop_chg_yoy',\n",
    "    'one_year_pop', 'two_years_pop','three_years_pop', 'four_years_pop', 'five_years_pop',\n",
    "    'one_year_emp', 'two_years_emp', 'three_years_emp', 'four_years_emp', 'five_years_emp',\n",
    "       'one_year_estab', 'two_years_estab', 'three_years_estab',\n",
    "       'four_years_estab', 'five_years_estab', 'one_year_pay', 'two_years_pay',\n",
    "       'three_years_pay', 'four_years_pay', 'five_years_pay',\n",
    "         'one_year_pop', 'one_year_inc', 'two_years_inc',\n",
    "    'three_years_inc','four_years_inc','five_years_inc',\n",
    "        'two_years_pop', 'three_years_pop', 'four_years_pop',\n",
    "    'five_years_pop', 'hh_income']].values\n",
    "\n",
    "y = df3[['five_years']].values\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.add(Dense(100, activation='relu', input_dim=X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.add(Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.add(Dense(y_train.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training and testing data using the X_scaler\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# One-hot encoding\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create a normal neural network with 2 inputs, 6 hidden nodes, and 2 outputs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "deep_model = Sequential()\n",
    "# deep_model.add(Dropout(rate=0.2, input_shape=(38,)))\n",
    "deep_model.add(Dense(units=6, activation='relu', input_dim=38))\n",
    "deep_model.add(Dense(units=6, activation='relu'))\n",
    "deep_model.add(Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.compile(optimizer='adam',\n",
    "                  loss='mean_absolute_error',\n",
    "                   metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    validation_split=0.33, \n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss, model_accuracy = deep_model.evaluate(X_test_scaled, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(deep_model.predict(X_test_scaled), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(deep_model.predict(X_train_scaled), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.r2_score(y_train, deep_model.predict(X_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.r2_score(y_test, deep_model.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
